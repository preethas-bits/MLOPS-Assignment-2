{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6889e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1af2b",
   "metadata": {},
   "source": [
    "# Create and save model as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79809438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'titanic_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Drop unnecessary columns and handle missing values\n",
    "X = data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'Sex', 'Embarked', 'Survived'])\n",
    "y = data['Survived']\n",
    "\n",
    "# Fill missing values with the mean\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the RandomForest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model to a pickle file\n",
    "with open('titanic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model saved as 'titanic_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94132d2",
   "metadata": {},
   "source": [
    "# Predict using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60360b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass       Age     SibSp     Parch      Fare  Prediction  Actual  \\\n",
      "0  0.813034  0.012390  0.379923  0.784700 -0.333901           0       1   \n",
      "1 -0.400551  0.112570 -0.470722 -0.479342 -0.425284           0       0   \n",
      "2  0.813034 -0.734533 -0.470722 -0.479342 -0.474867           0       0   \n",
      "3 -0.400551 -1.812666 -0.470722  0.784700  0.007966           1       1   \n",
      "4  0.813034 -1.196590  0.379923 -0.479342 -0.411002           0       1   \n",
      "5 -1.614136 -0.272477 -0.470722 -0.479342  0.890834           1       1   \n",
      "6  0.813034  0.012390 -0.470722 -0.479342 -0.478237           0       1   \n",
      "7  0.813034 -1.042571  1.230569 -0.479342 -0.280867           0       0   \n",
      "8  0.813034 -1.042571 -0.470722 -0.479342 -0.478237           1       1   \n",
      "9 -1.614136 -0.811543 -0.470722  2.048742 -0.121367           1       1   \n",
      "\n",
      "   Correct  \n",
      "0    False  \n",
      "1     True  \n",
      "2     True  \n",
      "3     True  \n",
      "4    False  \n",
      "5     True  \n",
      "6    False  \n",
      "7     True  \n",
      "8     True  \n",
      "9     True  \n"
     ]
    }
   ],
   "source": [
    "# Load the model from the pickle file\n",
    "with open('titanic_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "# Compare predictions with the actual test labels (y_test)\n",
    "comparison = (predictions == y_test.values)\n",
    "\n",
    "# Create a DataFrame to display X_test_scaled along with predictions and True/False comparison\n",
    "df = pd.DataFrame(X_test_scaled, columns=X_train.columns)  # Use same columns as X_train\n",
    "df['Prediction'] = predictions\n",
    "df['Actual'] = y_test.values\n",
    "df['Correct'] = comparison\n",
    "\n",
    "# Display the DataFrame (first 10 rows)\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df2bfe",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1672ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[86 19]\n",
      " [31 43]]\n",
      "\n",
      "Accuracy: 0.7207\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Did not survive       0.74      0.82      0.77       105\n",
      "       Survived       0.69      0.58      0.63        74\n",
      "\n",
      "       accuracy                           0.72       179\n",
      "      macro avg       0.71      0.70      0.70       179\n",
      "   weighted avg       0.72      0.72      0.72       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and print other performance metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report (includes precision, recall, F1-score)\n",
    "class_report = classification_report(y_test, predictions, target_names=['Did not survive', 'Survived'])\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518c578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
