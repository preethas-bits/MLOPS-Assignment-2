{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63616c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 395\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0e0754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.0.2 in c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\preethas\\appdata\\local\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6889e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import pickle\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1af2b",
   "metadata": {},
   "source": [
    "# Create and save model as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79809438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass   Age  SibSp  Parch     Fare  Sex_encoded  Embarked_encoded\n",
      "0       3  22.0      1      0   7.2500            1                 2\n",
      "1       1  38.0      1      0  71.2833            0                 0\n",
      "2       3  26.0      0      0   7.9250            0                 2\n",
      "3       1  35.0      1      0  53.1000            0                 2\n",
      "4       3  35.0      0      0   8.0500            1                 2\n",
      "Model saved as 'titanic_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Create a label encoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to the 'Sex' column\n",
    "data['Sex_encoded'] = label_encoder.fit_transform(data['Sex'])\n",
    "# Fit and transform the Embarked column\n",
    "data['Embarked_encoded'] = label_encoder.fit_transform(data['Embarked'])\n",
    "\n",
    "## Values: The Embarked column typically contains codes for different ports:\n",
    "## C: Cherbourg\n",
    "## Q: Queenstown \n",
    "## S: Southampton\n",
    "\n",
    "## C could be encoded as 0\n",
    "## Q could be encoded as 1\n",
    "## S could be encoded as 2\n",
    "    \n",
    "# Drop unnecessary columns and handle missing values\n",
    "X = data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'Sex','Survived','Embarked'])\n",
    "y = data['Survived']\n",
    "\n",
    "\n",
    "# Fill missing values with the mean\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "print(X.head())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the RandomForest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model to a pickle file\n",
    "with open('titanic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model saved as 'titanic_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94132d2",
   "metadata": {},
   "source": [
    "# Predict using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60360b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass       Age     SibSp     Parch      Fare  Sex_encoded  Prediction  \\\n",
      "0  0.813034  0.012390  0.379923  0.784700 -0.333901     0.724310           0   \n",
      "1 -0.400551  0.112570 -0.470722 -0.479342 -0.425284     0.724310           0   \n",
      "2  0.813034 -0.734533 -0.470722 -0.479342 -0.474867     0.724310           0   \n",
      "3 -0.400551 -1.812666 -0.470722  0.784700  0.007966    -1.380624           1   \n",
      "4  0.813034 -1.196590  0.379923 -0.479342 -0.411002    -1.380624           0   \n",
      "5 -1.614136 -0.272477 -0.470722 -0.479342  0.890834    -1.380624           1   \n",
      "6  0.813034  0.012390 -0.470722 -0.479342 -0.478237    -1.380624           1   \n",
      "7  0.813034 -1.042571  1.230569 -0.479342 -0.280867     0.724310           0   \n",
      "8  0.813034 -1.042571 -0.470722 -0.479342 -0.478237    -1.380624           1   \n",
      "9 -1.614136 -0.811543 -0.470722  2.048742 -0.121367    -1.380624           1   \n",
      "\n",
      "   Actual  Correct  \n",
      "0       1    False  \n",
      "1       0     True  \n",
      "2       0     True  \n",
      "3       1     True  \n",
      "4       1    False  \n",
      "5       1     True  \n",
      "6       1     True  \n",
      "7       0     True  \n",
      "8       1     True  \n",
      "9       1     True  \n"
     ]
    }
   ],
   "source": [
    "# Load the model from the pickle file\n",
    "with open('titanic_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "# Compare predictions with the actual test labels (y_test)\n",
    "comparison = (predictions == y_test.values)\n",
    "\n",
    "# Create a DataFrame to display X_test_scaled along with predictions and True/False comparison\n",
    "df = pd.DataFrame(X_test_scaled, columns=X_train.columns)  # Use same columns as X_train\n",
    "df['Prediction'] = predictions\n",
    "df['Actual'] = y_test.values\n",
    "df['Correct'] = comparison\n",
    "\n",
    "# Display the DataFrame (first 10 rows)\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df2bfe",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1672ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[90 15]\n",
      " [19 55]]\n",
      "\n",
      "Accuracy: 0.8101\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Did not survive       0.83      0.86      0.84       105\n",
      "       Survived       0.79      0.74      0.76        74\n",
      "\n",
      "       accuracy                           0.81       179\n",
      "      macro avg       0.81      0.80      0.80       179\n",
      "   weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and print other performance metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report (includes precision, recall, F1-score)\n",
    "class_report = classification_report(y_test, predictions, target_names=['Did not survive', 'Survived'])\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518c578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
